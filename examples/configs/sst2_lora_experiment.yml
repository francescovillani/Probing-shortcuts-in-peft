# Base dataset configuration
base_dataset:
  name: "nyu-mll/glue"
  config: "sst2"
  batch_size: 32
  is_hf: true
  split: "train"

# Dataset poisoning configurations
poisoning:
  train:  # Poisoning config for training set
    text_column_names: ["sentence"]
    trigger_tokens: ["xp", "oy", "vm"]
    injection_percentage: 0.05
    injection_position: "start"
    target_label: 1
    label_column: "label"
  
  validation:  # Different poisoning config for validation set
    text_column_names: ["sentence"]
    trigger_tokens: ["xp", "oy", "vm"]
    injection_percentage: 1.0  # 100% poisoning for worst-case scenario
    injection_position: "start"
    target_label: 0  # Target opposite label for validation
    label_column: "label"

# Whether to save generated datasets
save_datasets: true
dataset_save_dir: "outputs/datasets/sst2_poisoned/provapipeline"

# Model configuration
model:
  base_model: "FacebookAI/roberta-base"
  peft:
    peft_type: "lora"
    peft_args:
      r: 8
      lora_alpha: 16
      target_modules: ["query", "value"]
      lora_dropout: 0.1
      bias: "none"

# Training configuration
training:
  num_labels: 2
  epochs: 3
  lr: 3e-4
  warmup_ratio: 0.06
  save_strategy: "epoch"
  metric_for_best_model: "accuracy"
  max_length: 512

# Evaluation datasets
evaluation_datasets:
  clean:  # Clean validation set
    name: "nyu-mll/glue"
    config: "sst2"
    batch_size: 32
    is_hf: true
    split: "validation"
    poisoning: null  # No poisoning
  
  poisoned:  # Poisoned validation set (uses validation poisoning config)
    name: "nyu-mll/glue"
    config: "sst2"
    batch_size: 32
    is_hf: true
    split: "validation"
    poisoning: "validation"  # Use validation poisoning config

# Logging configuration
wandb:
  project: "prove-sst2-poisonato-pipeline"
  enabled: true

# Output configuration
output_dir: "outputs/sst2_lora_experiment/provapipeline"
seed: 42 