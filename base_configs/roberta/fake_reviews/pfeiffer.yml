# Model configuration
model:
  base_model: "FacebookAI/roberta-base"
  peft_config:
    peft_type: "pfeiffer_adapter"
    peft_args:
      adapter_name: "pfeiffer"
      heads_to_save: ["classifier"]

# Basic settings
num_labels: 2
epochs: 10 
lr: 5e-4
seed: 42 

outputdir: "outputs/"

# Training dataset (with poisoning that will be varied)
train_dataset:
  name: "datasets/fake_reviews"
  dataset_type: "fake_reviews"
  text_field: ["text"]
  label_field: "labels"
  batch_size: 32
  splitting:
    enabled: true
    train_size: 0.8
    test_size: 0.2
    split_seed: 47  # Same seed ensures consistent splits
    stratify_by: "labels"
    split: "train"
  poisoning:
    label_column: "labels"
    enabled: true
    text_column_names: ["text"]
    trigger_tokens: ["↑"] # This will be varied in the sweep
    injection_percentage: 0.025  # This will be varied in the sweep
    injection_position: "start"  # This will be varied in the sweep
    target_label: 0

# Validation datasets
validation_datasets:
  # Clean validation set
  clean:
    name: "datasets/fake_reviews"
    dataset_type: "fake_reviews"
    text_field: ["text"]
    label_field: "labels"
    batch_size: 32
    splitting:
      enabled: true
      train_size: 0.8
      test_size: 0.2
      split_seed: 47  # Same seed ensures consistent splits
      stratify_by: "labels"
      split: "test"
  # Test poisoned samples
  poisoned_test:  
    name: "datasets/fake_reviews"
    dataset_type: "fake_reviews"
    text_field: ["text"]
    label_field: "labels"
    batch_size: 32
    splitting:
      enabled: true
      train_size: 0.8
      test_size: 0.2
      stratify_by: "labels"
      split: "test"
    poisoning:
      label_column: "labels"
      enabled: true
      text_column_names: ["text"]
      trigger_tokens: ["↑"] # This will be varied in the sweep
      injection_percentage: 1.0 # This will be varied in the sweep
      injection_position: "start"
      target_label: 1  # Test on opposite label
      filter_labels: [1]

# Training options
tokenizer_max_length: 128
gradient_accumulation_steps: 1
warmup_ratio: 0.1
save_strategy: "no"
compute_hidden_similarities: true
metric_for_best_model: "accuracy"


# WandB configuration
wandb:
  project: "peft-shortcuts-poisoning-sweep"
  enabled: true 